spring:
  application:
    name: ai-ml-service
  
  profiles:
    active: dev
    
  datasource:
    url: jdbc:postgresql://localhost:5432/woltaxi_aiml
    username: woltaxi_user
    password: woltaxi_password
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 25
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000

  jpa:
    hibernate:
      ddl-auto: validate
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        use_sql_comments: true
        jdbc:
          batch_size: 50
        order_inserts: true
        order_updates: true
        generate_statistics: false

  redis:
    host: localhost
    port: 6379
    password: 
    database: 4
    jedis:
      pool:
        max-active: 20
        max-idle: 10
        min-idle: 2
        max-wait: -1ms
    timeout: 5000ms

  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all
      retries: 3
      batch-size: 32768
      linger-ms: 10
      buffer-memory: 67108864
    consumer:
      group-id: ai-ml-service-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      properties:
        spring.json.trusted.packages: "com.woltaxi.aiml.event"

  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=10000,expireAfterWrite=1h

  servlet:
    multipart:
      enabled: true
      max-file-size: 100MB
      max-request-size: 100MB
      file-size-threshold: 10MB

server:
  port: 8094
  servlet:
    context-path: /api/v1/ai-ml
  compression:
    enabled: true
    mime-types: text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json
    min-response-size: 2048

eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/
    register-with-eureka: true
    fetch-registry: true
    initial-instance-info-replication-interval-seconds: 30
    instance-info-replication-interval-seconds: 30
  instance:
    hostname: localhost
    prefer-ip-address: true
    lease-renewal-interval-in-seconds: 30
    lease-expiration-duration-in-seconds: 90
    metadata-map:
      version: ${project.version}
      instanceId: ${spring.application.name}:${server.port}

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,aiml
  endpoint:
    health:
      show-details: when-authorized
      probes:
        enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles-histogram:
        http.server.requests: true
      percentiles:
        http.server.requests: 0.5, 0.95, 0.99
      sla:
        http.server.requests: 100ms, 500ms, 1s, 2s, 5s

logging:
  level:
    com.woltaxi.aiml: DEBUG
    org.tensorflow: INFO
    org.deeplearning4j: INFO
    org.springframework.ai: DEBUG
    weka: WARN
    smile: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId:-},%X{spanId:-}] %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId:-},%X{spanId:-}] %logger{36} - %msg%n"
  file:
    name: logs/ai-ml-service.log
    max-size: 100MB
    max-history: 30

# AI/ML Service Configuration
woltaxi:
  aiml:
    # Model Storage Configuration
    models:
      storage-path: models/
      cache-size: 100
      download-timeout: 300s
      
    # TensorFlow Configuration
    tensorflow:
      enabled: true
      gpu-enabled: false
      model-server-url: http://localhost:8501
      
    # OpenAI Configuration
    openai:
      enabled: true
      api-key: ${OPENAI_API_KEY:}
      model: gpt-3.5-turbo
      max-tokens: 2000
      temperature: 0.7
      
    # Google Cloud AI
    google-cloud:
      enabled: true
      project-id: ${GOOGLE_CLOUD_PROJECT_ID:woltaxi-ai}
      credentials-path: ${GOOGLE_APPLICATION_CREDENTIALS:}
      
    # Azure Cognitive Services
    azure:
      enabled: true
      subscription-key: ${AZURE_COGNITIVE_SERVICES_KEY:}
      region: ${AZURE_REGION:eastus}
      
    # Computer Vision
    computer-vision:
      enabled: true
      face-detection: true
      object-detection: true
      ocr: true
      image-classification: true
      
    # Natural Language Processing
    nlp:
      enabled: true
      language-detection: true
      sentiment-analysis: true
      entity-recognition: true
      text-classification: true
      translation: true
      
    # Machine Learning Models
    ml-models:
      # Demand Prediction
      demand-prediction:
        enabled: true
        retrain-interval: daily
        historical-data-days: 90
        
      # Pricing Optimization
      pricing-optimization:
        enabled: true
        algorithm: reinforcement-learning
        update-frequency: hourly
        
      # Route Optimization
      route-optimization:
        enabled: true
        algorithm: genetic-algorithm
        real-time-updates: true
        
      # Fraud Detection
      fraud-detection:
        enabled: true
        algorithm: isolation-forest
        sensitivity: high
        
      # Customer Churn Prediction
      churn-prediction:
        enabled: true
        model-type: xgboost
        retrain-frequency: weekly
        
      # Driver Performance Prediction
      driver-performance:
        enabled: true
        features: [rating, completion-rate, earnings, trips]
        prediction-horizon: 30d
        
    # Real-time Analytics
    real-time-analytics:
      enabled: true
      window-size: 5m
      processing-delay: 1s
      
    # Batch Processing
    batch-processing:
      enabled: true
      schedule: "0 0 2 * * ?"
      chunk-size: 1000
      
    # Feature Engineering
    feature-engineering:
      enabled: true
      auto-feature-selection: true
      feature-scaling: true
      
    # Model Monitoring
    model-monitoring:
      enabled: true
      drift-detection: true
      performance-tracking: true
      alert-threshold: 0.1
      
    # A/B Testing
    ab-testing:
      enabled: true
      traffic-split: 0.1
      statistical-significance: 0.05

# Third Party AI Services
openai:
  api-key: ${OPENAI_API_KEY:}
  organization: ${OPENAI_ORGANIZATION:}
  timeout: 30s

google:
  cloud:
    project-id: ${GOOGLE_CLOUD_PROJECT_ID:woltaxi-ai}
    credentials-path: ${GOOGLE_APPLICATION_CREDENTIALS:google-cloud-key.json}
  maps:
    api-key: ${GOOGLE_MAPS_API_KEY:}
  translate:
    api-key: ${GOOGLE_TRANSLATE_API_KEY:}

azure:
  cognitive-services:
    key: ${AZURE_COGNITIVE_SERVICES_KEY:}
    region: ${AZURE_REGION:eastus}
    endpoint: ${AZURE_COGNITIVE_SERVICES_ENDPOINT:}

huggingface:
  api-key: ${HUGGINGFACE_API_KEY:}
  model-cache-dir: models/huggingface/

---
spring:
  config:
    activate:
      on-profile: docker
      
  datasource:
    url: jdbc:postgresql://postgres:5432/woltaxi_aiml
    username: woltaxi_user
    password: woltaxi_password
    
  redis:
    host: redis
    port: 6379
    
  kafka:
    bootstrap-servers: kafka:9092

eureka:
  client:
    service-url:
      defaultZone: http://eureka-server:8761/eureka/
  instance:
    hostname: ai-ml-service
    
server:
  port: 8094

woltaxi:
  aiml:
    models:
      storage-path: /app/models/
    tensorflow:
      model-server-url: http://tensorflow-serving:8501

---
spring:
  config:
    activate:
      on-profile: test
      
  datasource:
    url: jdbc:h2:mem:testdb
    username: sa
    password: 
    driver-class-name: org.h2.Driver
    
  jpa:
    hibernate:
      ddl-auto: create-drop
    database-platform: org.hibernate.dialect.H2Dialect